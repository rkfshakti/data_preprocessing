{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Demo\n",
    "\n",
    "This notebook demonstrates topic modeling techniques including LDA (Latent Dirichlet Allocation), topic visualization, and topic-sentiment correlation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.analysis import (\n",
    "    load_data, preprocess_df, lda_topics, topic_sentiment_correlation,\n",
    "    compute_vader_sentiment\n",
    ")\n",
    "\n",
    "# Generate data if needed\n",
    "DATA = Path('data') / 'synthetic_texts.csv'\n",
    "if not DATA.exists():\n",
    "    from generate_data import generate\n",
    "    generate(800)\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data(DATA)\n",
    "df = preprocess_df(df)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Label distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topics using LDA\n",
    "topics = lda_topics(df['joined_tokens'], n_topics=5, n_top_words=10)\n",
    "print(\"LDA Topics discovered:\")\n",
    "for i, topic_words in enumerate(topics):\n",
    "    print(f\"Topic {i}: {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics using word clouds\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, topic_words in enumerate(topics):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    text = ' '.join(topic_words)\n",
    "    wordcloud = WordCloud(width=400, height=300, background_color='white').generate(text)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Topic {i}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic-Sentiment Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sentiment scores\n",
    "df_sentiment = compute_vader_sentiment(df)\n",
    "\n",
    "# Analyze topic-sentiment correlation\n",
    "topic_corr = topic_sentiment_correlation(df_sentiment, n_topics=5)\n",
    "print(\"Topic-Sentiment Correlation:\")\n",
    "print(topic_corr)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if x < 0 else 'green' for x in topic_corr['corr_with_sentiment']]\n",
    "plt.bar(range(len(topic_corr)), topic_corr['corr_with_sentiment'], color=colors)\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Correlation with Sentiment')\n",
    "plt.title('Topic-Sentiment Correlation')\n",
    "plt.xticks(range(len(topic_corr)), [f'Topic {i}' for i in range(len(topic_corr))])\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Distribution by Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA and get document-topic distributions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=2000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['joined_tokens'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "doc_topic_dist = lda.fit_transform(X)\n",
    "\n",
    "# Add topic distributions to dataframe\n",
    "topic_cols = [f'topic_{i}' for i in range(5)]\n",
    "for i, col in enumerate(topic_cols):\n",
    "    df[col] = doc_topic_dist[:, i]\n",
    "\n",
    "# Analyze topic distribution by domain\n",
    "topic_by_domain = df.groupby('domain')[topic_cols].mean()\n",
    "print(\"Topic distribution by domain:\")\n",
    "print(topic_by_domain)\n",
    "\n",
    "# Visualize topic distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "topic_by_domain.T.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Topic Distribution by Domain')\n",
    "plt.ylabel('Mean Topic Probability')\n",
    "plt.xlabel('Topic')\n",
    "plt.legend(title='Domain')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess topic coherence\n",
    "def calculate_topic_coherence(topics, vectorizer, X):\n",
    "    \"\"\"Simple topic coherence metric based on pairwise word co-occurrence\"\"\"\n",
    "    coherence_scores = []\n",
    "    for topic_words in topics:\n",
    "        if len(topic_words) < 2:\n",
    "            coherence_scores.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Get word indices\n",
    "        word_indices = [vectorizer.vocabulary_.get(word, -1) for word in topic_words[:10]]\n",
    "        word_indices = [idx for idx in word_indices if idx != -1]\n",
    "        \n",
    "        if len(word_indices) < 2:\n",
    "            coherence_scores.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Calculate pairwise co-occurrence\n",
    "        cooccurrence = X[:, word_indices].sum(axis=0)\n",
    "        pairwise_cooccurrence = X[:, word_indices].T @ X[:, word_indices]\n",
    "        \n",
    "        coherence = 0\n",
    "        count = 0\n",
    "        for i in range(len(word_indices)):\n",
    "            for j in range(i+1, len(word_indices)):\n",
    "                if pairwise_cooccurrence[i, j] > 0:\n",
    "                    coherence += np.log((pairwise_cooccurrence[i, j] + 1) / (cooccurrence[i] + 1))\n",
    "                    count += 1\n",
    "        \n",
    "        coherence_scores.append(coherence / count if count > 0 else 0)\n",
    "    \n",
    "    return coherence_scores\n",
    "\n",
    "# Calculate coherence scores\n",
    "coherence_scores = calculate_topic_coherence(topics, vectorizer, X)\n",
    "print(\"Topic Coherence Scores:\")\n",
    "for i, score in enumerate(coherence_scores):\n",
    "    print(f\"Topic {i}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Topic Visualization (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive topic visualization\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Create interactive topic distribution plot\n",
    "    topic_melt = topic_by_domain.reset_index().melt(id_vars=['domain'], \n",
    "                                                   value_vars=topic_cols,\n",
    "                                                   var_name='topic', \n",
    "                                                   value_name='probability')\n",
    "    \n",
    "    fig = px.bar(topic_melt, x='topic', y='probability', color='domain', \n",
    "                title='Topic Distribution by Domain', barmode='group')\n",
    "    fig.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Plotly not available for interactive visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Basic LDA topic extraction\n",
    "2. Topic visualization with word clouds\n",
    "3. Topic-sentiment correlation analysis\n",
    "4. Topic distribution across domains\n",
    "5. Topic coherence assessment\n",
    "6. Interactive visualization\n",
    "\n",
    "Key insights:\n",
    "- Different domains have distinct topic distributions\n",
    "- Topics can be ranked by their sentiment correlation\n",
    "- Coherence scores help assess topic quality\n",
    "- Interactive visualizations provide deeper insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}