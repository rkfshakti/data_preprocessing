{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates comprehensive sentiment analysis using VADER, domain-specific sentiment patterns, sentiment trend analysis, and advanced visualization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.analysis import preprocess_df, add_sentiment_scores\n",
    "from src.preprocess import clean_text\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load and preprocess data\n",
    "DATA = Path('data') / 'synthetic_texts.csv'\n",
    "if not DATA.exists():\n",
    "    from generate_data import generate\n",
    "    generate(1000)\n",
    "\n",
    "df = pd.read_csv(DATA)\n",
    "df = preprocess_df(df)\n",
    "\n",
    "# Add sentiment scores\n",
    "df = add_sentiment_scores(df)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Domains: {df['domain'].unique()}\")\n",
    "print(f\"Labels: {df['label'].unique()}\")\n",
    "print(f\"\\nSentiment columns: {[col for col in df.columns if 'sentiment' in col.lower()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentiment Distribution Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Overall sentiment distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Overall sentiment distribution\n",
    "axes[0,0].hist(df['sentiment_score'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Overall Sentiment Distribution')\n",
    "axes[0,0].set_xlabel('Sentiment Score')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Sentiment by domain\n",
    "domains = df['domain'].unique()\n",
    "for domain in domains:\n",
    "    domain_data = df[df['domain'] == domain]\n",
    "    axes[0,1].hist(domain_data['sentiment_score'], bins=20, alpha=0.6, label=domain)\n",
    "axes[0,1].set_title('Sentiment Distribution by Domain')\n",
    "axes[0,1].set_xlabel('Sentiment Score')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Sentiment by label\n",
    "labels = df['label'].unique()\n",
    "for label in labels:\n",
    "    label_data = df[df['label'] == label]\n",
    "    axes[1,0].hist(label_data['sentiment_score'], bins=20, alpha=0.6, label=label)\n",
    "axes[1,0].set_title('Sentiment Distribution by Label')\n",
    "axes[1,0].set_xlabel('Sentiment Score')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Sentiment compound distribution\n",
    "axes[1,1].hist(df['sentiment_compound'], bins=30, alpha=0.7, color='lightcoral')\n",
    "axes[1,1].set_title('Compound Sentiment Distribution')\n",
    "axes[1,1].set_xlabel('Compound Sentiment Score')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSentiment Summary Statistics:\")\n",
    "print(df[['sentiment_score', 'sentiment_compound']].describe())\n",
    "\n",
    "# Sentiment classification counts\n",
    "print(\"\\nSentiment Classification Counts:\")\n",
    "print(df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-Specific Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Domain-Specific Sentiment Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Sentiment statistics by domain\n",
    "domain_sentiment = df.groupby('domain')['sentiment_score'].agg([\n",
    "    'mean', 'std', 'min', 'max', 'count'\n",
    "]).round(3)\n",
    "\n",
    "print(\"Sentiment Statistics by Domain:\")\n",
    "print(domain_sentiment)\n",
    "\n",
    "# Visualize domain sentiment differences\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df, x='domain', y='sentiment_score')\n",
    "plt.title('Sentiment Distribution by Domain')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Violin plot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(data=df, x='domain', y='sentiment_score')\n",
    "plt.title('Sentiment Density by Domain')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sentiment by domain and label\n",
    "print(\"\\nSentiment by Domain and Label:\")\n",
    "domain_label_sentiment = df.groupby(['domain', 'label'])['sentiment_score'].agg([\n",
    "    'mean', 'std', 'count'\n",
    "]).round(3)\n",
    "print(domain_label_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentiment Trend Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create synthetic time data for trend analysis\n",
    "df['date'] = pd.date_range(start='2024-01-01', periods=len(df), freq='H')\n",
    "df['day'] = df['date'].dt.date\n",
    "df['hour'] = df['date'].dt.hour\n",
    "\n",
    "# Daily sentiment trends\n",
    "daily_sentiment = df.groupby('day')['sentiment_score'].agg(['mean', 'std', 'count'])\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['mean'], marker='o', linewidth=2)\n",
    "plt.fill_between(daily_sentiment.index, \n",
    "                 daily_sentiment['mean'] - daily_sentiment['std'],\n",
    "                 daily_sentiment['mean'] + daily_sentiment['std'],\n",
    "                 alpha=0.3)\n",
    "plt.title('Daily Sentiment Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hourly sentiment patterns\n",
    "hourly_sentiment = df.groupby('hour')['sentiment_score'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(hourly_sentiment.index, hourly_sentiment.values, alpha=0.7)\n",
    "plt.title('Hourly Sentiment Pattern')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sentiment trends by domain\n",
    "plt.figure(figsize=(15, 8))\n",
    "for domain in domains:\n",
    "    domain_data = df[df['domain'] == domain]\n",
    "    daily_domain = domain_data.groupby('day')['sentiment_score'].mean()\n",
    "    plt.plot(daily_domain.index, daily_domain.values, marker='o', linewidth=2, label=domain)\n",
    "\n",
    "plt.title('Daily Sentiment Trends by Domain')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Advanced Sentiment Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Sentiment correlation with text length\n",
    "df['text_length'] = df['text'].str.len()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['text_length'], df['sentiment_score'], alpha=0.6)\n",
    "plt.title('Sentiment vs Text Length')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df['text_length'].corr(df['sentiment_score'])\n",
    "print(f\"Correlation between text length and sentiment: {correlation:.3f}\")\n",
    "\n",
    "# Sentiment by word count\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x=pd.cut(df['word_count'], bins=5), y='sentiment_score')\n",
    "plt.title('Sentiment by Word Count Categories')\n",
    "plt.xlabel('Word Count Range')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sentiment extremes analysis\n",
    "print(\"\\nMost Positive Texts:\")\n",
    "most_positive = df.nlargest(5, 'sentiment_score')\n",
    "for idx, row in most_positive.iterrows():\n",
    "    print(f\"\\nScore: {row['sentiment_score']:.3f}\")\n",
    "    print(f\"Text: {row['text'][:100]}...\")\n",
    "    print(f\"Domain: {row['domain']}, Label: {row['label']}\")\n",
    "\n",
    "print(\"\\nMost Negative Texts:\")\n",
    "most_negative = df.nsmallest(5, 'sentiment_score')\n",
    "for idx, row in most_negative.iterrows():\n",
    "    print(f\"\\nScore: {row['sentiment_score']:.3f}\")\n",
    "    print(f\"Text: {row['text'][:100]}...\")\n",
    "    print(f\"Domain: {row['domain']}, Label: {row['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentiment Classification Performance\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Analyze sentiment classification consistency\n",
    "print(\"Sentiment Label Distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# Compare with manual labels (if we had them)\n",
    "# For synthetic data, we can analyze patterns\n",
    "\n",
    "# Sentiment by domain and manual label\n",
    "cross_tab = pd.crosstab(df['domain'], df['sentiment_label'], normalize='index')\n",
    "print(\"\\nSentiment Distribution by Domain:\")\n",
    "print(cross_tab.round(3))\n",
    "\n",
    "# Visualize sentiment label distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "cross_tab_abs = pd.crosstab(df['domain'], df['sentiment_label'])\n",
    "cross_tab_abs.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.title('Sentiment Label Distribution by Domain')\n",
    "plt.xlabel('Domain')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Sentiment Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sentiment classification accuracy analysis\n",
    "# (This would require ground truth labels for real data)\n",
    "print(\"\\nNote: For real-world data, you would compare VADER sentiment labels\")\n",
    "print(\"with human-annotated labels to calculate classification accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Summary\n",
    "\n",
    "This comprehensive sentiment analysis demonstrates:\n",
    "\n",
    "1. **Overall Sentiment Patterns**: Distribution of sentiment scores across the dataset\n",
    "2. **Domain-Specific Analysis**: How sentiment varies across different domains\n",
    "3. **Temporal Trends**: Daily and hourly sentiment patterns\n",
    "4. **Advanced Correlations**: Relationship between sentiment and text characteristics\n",
    "5. **Extreme Analysis**: Examination of most positive and negative texts\n",
    "6. **Classification Performance**: Analysis of sentiment label distribution\n",
    "\n",
    "Key insights:\n",
    "- VADER provides effective sentiment analysis for short texts\n",
    "- Different domains show distinct sentiment patterns\n",
    "- Temporal trends can reveal important patterns in customer feedback\n",
    "- Text length and sentiment show interesting correlations\n",
    "- Extreme sentiment cases provide valuable insights for business improvement\n",
    "\n",
    "Next steps could include:\n",
    "- Integration with custom sentiment dictionaries\n",
    "- Real-time sentiment monitoring\n",
    "- Sentiment-based alert systems\n",
    "- Comparative analysis with other sentiment analysis tools\n",
    "- Multi-language sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}